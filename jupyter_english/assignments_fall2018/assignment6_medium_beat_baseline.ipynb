{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\" />\n",
    "    \n",
    "## [mlcourse.ai](https://mlcourse.ai) ‚Äì Open Machine Learning Course \n",
    "Author: [Yury Kashnitskiy](https://yorko.github.io) (@yorko). Edited by Sergey Kolchenko (@KolchenkoSergey). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Assignment #6\n",
    "### <center> Beating baselines in \"How good is your Medium article?\"\n",
    "    \n",
    "<img src='../../img/medium_claps.jpg' width=40% />\n",
    "\n",
    "\n",
    "[Competition](https://www.kaggle.com/c/how-good-is-your-medium-article). The task is to beat \"A6 baseline\" (~1.45 Public LB score). Do not forget about our shared [\"primitive\" baseline](https://www.kaggle.com/kashnitsky/ridge-countvectorizer-baseline) - you'll find something valuable there.\n",
    "\n",
    "**Your task:**\n",
    " 1. \"Freeride\". Come up with good features to beat the baseline \"A6 baseline\" (for now, public LB is only considered)\n",
    " 2. You need to name your [team](https://www.kaggle.com/c/how-good-is-your-medium-article/team) (out of 1 person) in full accordance with the [course rating](https://drive.google.com/open?id=19AGEhUQUol6_kNLKSzBsjcGUU3qWy3BNUg8x8IFkO3Q). You can think of it as a part of the assignment. 16 credits for beating the mentioned baseline and correct team naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, BayesianRidge, SGDRegressor, HuberRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will help to throw away all HTML tags from an article content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(path, name):\n",
    "    with open(f\"{path}{name}\", \"rb\") as file:\n",
    "        object_ = pickle.load(file)\n",
    "    return object_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        text = ' '.join(self.fed)\n",
    "        return re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supplementary function to read a JSON line without crashing on escape characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:        \n",
    "        result = json.loads(line)\n",
    "    except Exception as e:      \n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')',''))      \n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)     \n",
    "        return read_json_line(line=new_line)\n",
    "    return result\n",
    "\n",
    "def del_spaces(string):\n",
    "    return re.sub(r\"\\s+\", \" \", string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features `content`, `published`, `title` and `author`, write them to separate files for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_write(path_to_data,\n",
    "                               inp_filename, is_train=True):\n",
    "    \n",
    "    features = ['content', 'published', 'title', 'author']\n",
    "    prefix = 'train' if is_train else 'test'\n",
    "    feature_files = [open(os.path.join(path_to_data,\n",
    "                                       '{}_{}.txt'.format(prefix, feat)),\n",
    "                          'w', encoding='utf-8')\n",
    "                     for feat in features]\n",
    "    \n",
    "    with open(os.path.join(path_to_data, inp_filename), \n",
    "              encoding='utf-8') as inp_json_file:\n",
    "\n",
    "        for line in tqdm_notebook(inp_json_file):\n",
    "            json_data = read_json_line(line)\n",
    "            content = strip_tags(json_data[\"content\"]).lower()\n",
    "            title = del_spaces(json_data[\"title\"].replace(\"‚Äì\", \"\")).lower()\n",
    "            \n",
    "            feature_files[0].write(content + \"\\n\")\n",
    "            feature_files[1].write(json_data[\"published\"][\"$date\"].lower() + \"\\n\")\n",
    "            feature_files[2].write(title + \"\\n\")\n",
    "            feature_files[3].write(json_data[\"meta_tags\"][\"author\"].strip().lower() + \"\\n\")\n",
    "            \n",
    "    for file in feature_files:\n",
    "        file.close()\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATA = '/Users/alex/All/programming/Python/Jupyter /kaggle_medium/raw_data/' # modify this if you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb13b8c7feb42d7877cd8617b441d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1703it [35:04,  1.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Exception ignored in: <function tqdm.__del__ at 0x113987268>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/_tqdm.py\", line 889, in __del__\n",
      "    self.close()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/_tqdm.py\", line 1095, in close\n",
      "    self._decr_instances(self)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/_tqdm.py\", line 454, in _decr_instances\n",
      "    cls.monitor.exit()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tqdm/_monitor.py\", line 52, in exit\n",
      "    self.join()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 1029, in join\n",
      "    raise RuntimeError(\"cannot join current thread\")\n",
      "RuntimeError: cannot join current thread\n"
     ]
    }
   ],
   "source": [
    "# extract_features_and_write(PATH_TO_DATA, 'train.json', is_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bcc20ccec34e08a4a5221d7a08aeb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extract_features_and_write(PATH_TO_DATA, 'test.json', is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the following groups of features:**\n",
    "    - Tf-Idf with article content (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Tf-Idf with article titles (ngram_range=(1, 2), max_features=100000 but you can try adding more)\n",
    "    - Time features: publication hour, whether it's morning, day, night, whether it's a weekend\n",
    "    - Bag of authors (i.e. One-Hot-Encoded author names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ú–Ω–æ–≥–æ –≥–æ–≤–Ω–æ–∫–æ–¥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 44s, sys: 1min 21s, total: 11min 5s\n",
      "Wall time: 11min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# You code here\n",
    "tf_idf_content = TfidfVectorizer(ngram_range=(1,2), max_features=100000)\n",
    "\n",
    "with open(PATH_TO_DATA + \"train_content.txt\", \"r\") as content:\n",
    "    X_train_content_sparse = tf_idf_content.fit_transform(content)\n",
    "\n",
    "with open(PATH_TO_DATA + \"test_content.txt\", \"r\") as content:\n",
    "    X_test_content_sparse = tf_idf_content.transform(content)\n",
    "    \n",
    "with open(PATH_TO_DATA + \"train_content_idf.pkl\", \"wb\") as file:\n",
    "    pickle.dump(X_train_content_sparse, file)\n",
    "    \n",
    "with open(PATH_TO_DATA + \"test_content_idf.pkl\", \"wb\") as file:\n",
    "    pickle.dump(X_test_content_sparse, file)    \n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.41 s, sys: 6.92 s, total: 15.3 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf_idf_titles = TfidfVectorizer(ngram_range=(1, 2), max_features=100000)\n",
    "\n",
    "with open(PATH_TO_DATA + \"train_title.txt\", \"r\") as titles:\n",
    "    X_train_title_sparse = tf_idf_titles.fit_transform(titles)\n",
    "    \n",
    "with open(PATH_TO_DATA + \"test_title.txt\", \"r\") as titles:\n",
    "    X_test_title_sparse = tf_idf_titles.transform(titles)\n",
    "    \n",
    "with open(PATH_TO_DATA + \"train_title_idf.pkl\", \"wb\") as file:\n",
    "    pickle.dump(X_train_title_sparse, file)\n",
    "    \n",
    "with open(PATH_TO_DATA + \"test_title_idf.pkl\", \"wb\") as file:\n",
    "    pickle.dump(X_test_title_sparse, file)    \n",
    "\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 185 ms, sys: 28.7 ms, total: 214 ms\n",
      "Wall time: 219 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "with open(PATH_TO_DATA + \"train_author.txt\", \"r\") as authors:\n",
    "    authors_train = pd.read_csv(authors, sep=\"\\n\", header=None)\n",
    "    \n",
    "with open(PATH_TO_DATA + \"test_author.txt\", \"r\") as authors:\n",
    "    authors_test = pd.read_csv(authors, sep=\"\\n\", header=None)\n",
    "     \n",
    "split_indx = len(authors_train)\n",
    "authors_full = ohe.fit_transform(pd.concat([authors_train, authors_test], axis=0))\n",
    "\n",
    "    \n",
    "X_train_author_sparse = authors_full[:split_indx]\n",
    "X_test_author_sparse = authors_full[split_indx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_!shita', 'x0_#angels', 'x0_#cphftw', ..., 'x0_üòé nate andorsky',\n",
       "       'x0_üòé sam hurley üòé', 'x0_üöÄ marine wetzel ‚òÄÔ∏è'], dtype=object)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_content_sparse = load_obj(PATH_TO_DATA, \"train_content_idf.pkl\")\n",
    "X_test_content_sparse = load_obj(PATH_TO_DATA, \"test_content_idf.pkl\")\n",
    "\n",
    "X_train_title_sparse = load_obj(PATH_TO_DATA, \"train_title_idf.pkl\")\n",
    "X_test_title_sparse = load_obj(PATH_TO_DATA, \"test_title_idf.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join all sparse matrices.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del time features, just test run for now\n",
    "X_train_sparse = hstack([X_train_content_sparse, X_train_title_sparse,\n",
    "                         X_train_author_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sparse = hstack([X_test_content_sparse, X_test_title_sparse,\n",
    "                        X_test_author_sparse]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62313, 243859)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read train target and split data for validation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'), \n",
    "                           index_col='id')\n",
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part_size = int(0.7 * train_target.shape[0])\n",
    "X_train_part_sparse = X_train_sparse[:train_part_size, :]\n",
    "y_train_part = y_train[:train_part_size]\n",
    "X_valid_sparse =  X_train_sparse[train_part_size:, :]\n",
    "y_valid = y_train[train_part_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train a simple Ridge model and check MAE on the validation set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.9 s, sys: 1.64 s, total: 46.6 s\n",
      "Wall time: 49.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# You code here\n",
    "model = Ridge()\n",
    "\n",
    "model.fit(X_train_part_sparse, y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_valid_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0705941173274953"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the same Ridge with all available data, make predictions for the test set and form a submission file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You code here\n",
    "model_full = Ridge()\n",
    "model_full.fit(X_train_sparse, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43859,)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model_full.coef_[X_test_content_sparse.shape[1] + X_train_title_sparse.shape[1]:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = model_full.predict(X_test_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_DATA, \n",
    "                                                      'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "    \n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(y_test, os.path.join(PATH_TO_DATA,\n",
    "                                                    'assignment6_medium_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now's the time for dirty Kaggle hacks. Form a submission file with all zeroes. Make a submission. What do you get if you think about it? How is it going to help you with modifying your predictions?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(np.zeros_like(y_test), \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'medium_all_zeros_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify predictions in an appropriate way (based on your all-zero submission) and make a new submission.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1312977756494194"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.33328 - y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_test_pred_modif = y_test + 1.13129# You code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.333272224350581"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_test_pred_modif.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ridge_test_pred_modif);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission_file(ridge_test_pred_modif, \n",
    "                      os.path.join(PATH_TO_DATA,\n",
    "                                   'assignment6_medium_submission_with_hack.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for the assignment. Much more credits will be given to the winners in this competition, check [course roadmap](https://mlcourse.ai/roadmap). Do not spoil the assignment and the competition - don't share high-performing kernels (with MAE < 1.5).\n",
    "\n",
    "Some ideas for improvement:\n",
    "\n",
    "- Engineer good features, this is the key to success. Some simple features will be based on publication time, authors, content length and so on\n",
    "- You may not ignore HTML and extract some features from there\n",
    "- You'd better experiment with your validation scheme. You should see a correlation between your local improvements and LB score\n",
    "- Try TF-IDF, ngrams, Word2Vec and GloVe embeddings\n",
    "- Try various NLP techniques like stemming and lemmatization\n",
    "- Tune hyperparameters. In our example, we've left only 50k features and used C=1 as a regularization parameter, this can be changed\n",
    "- SGD and Vowpal Wabbit will learn much faster\n",
    "- Play around with blending and/or stacking. An intro is given in [this Kernel](https://www.kaggle.com/kashnitsky/ridge-and-lightgbm-simple-blending) by @yorko \n",
    "- In our course, we don't cover neural nets. But it's not obliged to use GRUs/LSTMs/whatever in this competition.\n",
    "\n",
    "Good luck!\n",
    "\n",
    "<img src='../../img/kaggle_shakeup.png' width=50%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
